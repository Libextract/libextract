{"name":"libextract","tagline":"A Python data extraction library","body":"Libextract: elegant text extraction\r\n===================================\r\n\r\n![travis](https://travis-ci.org/datalib/libextract.svg)\r\n    \r\n```\r\n        ___ __              __                  __\r\n       / (_) /_  ___  _  __/ /__________ ______/ /_\r\n      / / / __ \\/ _ \\| |/_/ __/ ___/ __ `/ ___/ __/\r\n     / / / /_/ /  __/>  </ /_/ /  / /_/ / /__/ /_\r\n    /_/_/_.___/\\___/_/|_|\\__/_/   \\__,_/\\___/\\__/\r\n```\r\n\r\nLibextract is a statistical extraction library that works\r\non HTML and XML documents, written in Python and originating\r\nfrom [eatiht](https://github.com/rodricios/eatiht). The philosophy and aim is to provide declaratively\r\ncomposed, simple and pipelined functions for users to describe\r\ntheir extraction algorithms.\r\n\r\nOverview\r\n--------\r\n\r\n`libextract.extract(doc)`\r\n    Extracts text (by default) from a given HT/XML string *doc*.\r\n    What is extracted and how it is extracted can be configured\r\n    using the *strategy* parameter, which accepts an iterable\r\n    of functions to be piped to one another (the result of the\r\n    previous is the argument of the next).\r\n\r\nInstallation\r\n------------\r\n\r\n    pip install libextract\r\n\r\nUsage\r\n-----\r\n\r\nExtracting the text from a wikipedia page:\r\n\r\n```python\r\n    from requests import get\r\n    from libextract import extract\r\n\r\n    r = get('http://en.wikipedia.org/wiki/Classifier_(linguistics)')\r\n    text = extract(r.content)\r\n```\r\nGetting the node that (most likely) contains the text nodes that\r\ncontain the text of the article:\r\n\r\n```python\r\n\r\n    from libextract.strategies import ARTICLE_NODE\r\n\r\n    node = extract(r.content, strategy=ARTICLE_NODE)\r\n```\r\nTo serialize the node into JSON format:\r\n\r\n```python\r\n\r\n    >>> from libextract.formatters import node_json\r\n    >>> node_json(node, depth=1)\r\n    {'children': [...],\r\n     'class': ['mw-content-ltr'],\r\n     'id': ['mw-content-text'],\r\n     'tag': 'div',\r\n     'text': None,\r\n     'xpath': '/html/body/div[3]/div[3]/div[4]'}\r\n```\r\n\r\nUsing tabular extraction to get the nodes containing tabular data\r\npresent in the HT/XML document:\r\n\r\n```python\r\n\r\n    from libextract.strategies import TABULAR\r\n\r\n    height_data = get(\"http://en.wikipedia.org/wiki/Human_height\")\r\n    tabs = list(extract(height_data.content, strategy=TABULAR))\r\n```\r\n\r\nTo convert HT/XML element to python ``list``\r\n\r\n```python\r\n    >>> from libextract.formatters import table_list\r\n    >>> table_list(tabs[0])\r\n    [['Country/Region',\r\n      'Average male height',\r\n      'Average female height',\r\n      'Stature ratio (male to female)',\r\n      'Sample population / age range',\r\n      ...]]\r\n```\r\n\r\nViewing the table in your browser:\r\n\r\n```python\r\n    from lxml.html import open_in_browser\r\n    open_in_browser(tabs[0])\r\n```\r\n","google":"UA-61980230-1","note":"Don't delete this file! It's used internally to help with page regeneration."}